Got it. I’ll write a research-style report, in the style of NeurIPS papers, explaining the rationale for decomposing legal statutes into Minimum Executable Units (MEUs) and executing them via LLM-based agents. I’ll structure the content around four domains: legal reasoning, LLM workflow planning, knowledge representation (light on KG), and compliance research in finance/accounting. 

I will focus on recent and relevant scholarly works, drawing from top-tier venues such as NeurIPS, ICLR, EMNLP, ACL, and arXiv. The legal and regulatory context will center on financial compliance from the Beijing Stock Exchange, U.S. FINRA, and EU-level rules.

I'll let you know once the draft is ready.

# Theoretical Rationale for MEU Decomposition and LLM Agent Execution

## Legal Theory and Formalism for Rule Decomposition  
**Formalizing Legal Rules:** In legal theory, formalism treats laws as rule systems that can be logically structured. Early **legal expert systems** demonstrated that statutes and regulations could be encoded as logical rules to enable automated reasoning ([](https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA241230#:~:text=Expert%20systems%20have%20been%20a,1%2C2%5D%2C%20which%20makes%20the)). Each rule was represented in a structured, interpretable form (e.g. as *if-conditions-then obligations*), providing clear reasoning traces. However, maintaining such rule bases proved challenging due to the **Knowledge Representation Bottleneck (KRB)** – the laborious process of acquiring, formalizing, and updating expert knowledge ([](https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA241230#:~:text=reasoning%20pro%02cesses%2C%20these%20systems%20face,built%20on%20vast%20amounts%20of)). This bottleneck limited the scalability of rule-based legal automation, especially as laws evolved. Recent research seeks to overcome the KRB by leveraging machine learning to help formalize legal texts ([](https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA241230#:~:text=reasoning%20pro%02cesses%2C%20these%20systems%20face,built%20on%20vast%20amounts%20of)) ([[2311.04911] From Text to Structure: Using Large Language Models to Support the Development of Legal Expert Systems](https://arxiv.org/abs/2311.04911#:~:text=,legislation%2C%20according%20to%20the%20JusticeBot)). For example, Janatian *et al.* use GPT-4 to automatically extract *structured representations* (so-called “legal pathways”) from legislation, achieving about 60% agreement with human experts ([[2311.04911] From Text to Structure: Using Large Language Models to Support the Development of Legal Expert Systems](https://arxiv.org/abs/2311.04911#:~:text=,legislation%2C%20according%20to%20the%20JusticeBot)) ([[2311.04911] From Text to Structure: Using Large Language Models to Support the Development of Legal Expert Systems](https://arxiv.org/abs/2311.04911#:~:text=methodology%20for%20legal%20decision%20support,that%20are%20transparent%20and%20explainable)). This suggests modern LLMs can assist in translating verbose legal provisions into formal, executable rules.

**Minimum Executable Units (MEUs):** Building on legal formalism, we define a **MEU** as the smallest enforceable unit of a legal rule. Each MEU encapsulates a single normative statement in a self-contained format that is amenable to computational checking. Concretely, an MEU consists of the following elements:

- **Subject:** the party or entity to whom the rule applies (e.g. a broker, a company, an officer).  
- **Condition:** the context or triggering scenario under which the rule is active (e.g. “when trading above \$10,000 in volume” or “if personal data is being processed”).  
- **Constraint:** the normative directive or prohibition that must be adhered to (e.g. “must file a report within 24 hours” or “shall not disclose client data without consent”).  
- **Contextual Info:** any necessary context for interpretation, such as cross-references, definitions, or exceptions that clarify the above elements.

By decomposing complex regulations into MEUs, we obtain atomic rules that are **explicit and testable**. This decomposition aligns with the structure of legal norms in deontic logic, which often take an *agent–condition–obligation* form. It also addresses a key limitation of naive text-based approaches: legal sentences often cannot be understood in isolation ([Rethinking Legal Compliance Automation: Opportunities with Large Language Models](https://arxiv.org/html/2404.14356v1#:~:text=First%2C%20interpreting%20sentences%20often%20requires,the%20mentioned%20measures%20are%20about)). For instance, a rule might say, *“Depending on the classification, buildings must have security measures. These measures include X, Y, Z.”* The second sentence (“These measures include…”) is only meaningful when interpreted with the first ([Rethinking Legal Compliance Automation: Opportunities with Large Language Models](https://arxiv.org/html/2404.14356v1#:~:text=First%2C%20interpreting%20sentences%20often%20requires,the%20mentioned%20measures%20are%20about)). By grouping such provisions into one MEU with shared context, we preserve essential cross-sentence meaning. Indeed, legal texts contain many cross-references and definitions that span multiple sentences ([Rethinking Legal Compliance Automation: Opportunities with Large Language Models](https://arxiv.org/html/2404.14356v1#:~:text=Third%2C%20legal%20texts%20are%20frequently,meaning%20of%20a%20given%20provision)). An MEU ensures those dependencies are bundled together, so that an automated check considers all requisite context when evaluating compliance. In sum, MEUs provide a formalism-friendly granularity: each unit is *small enough to be tractable* (a single obligation or prohibition), yet *rich enough to be semantically self-contained* for enforcement purposes.

## LLM-Based Agent Workflow Planning and Execution  
**LLMs as Reasoning Agents:** Large Language Models have recently been used not just for answering questions, but as **agents** that can plan and execute complex workflows. Rather than applying a single giant prompt to a whole regulation, an LLM agent can iterate through sub-tasks: e.g. interpret a rule, fetch relevant facts, apply the rule, and report results. This step-by-step reasoning mirrors the approach of classical AI planning systems, but is guided by the LLM’s natural language understanding. Techniques like **Chain-of-Thought prompting** highlight how breaking a task into intermediate reasoning steps dramatically improves LLM performance on complex problems ([Large Language Model based Multi-Agents: A Survey of Progress and Challenges](https://arxiv.org/html/2402.01680v2#:~:text=,Information%20Processing%20Systems%2C%2035%3A24824%E2%80%9324837%2C%202022)). By having the LLM “think aloud” through the conditions and constraints of a rule, we reduce errors and improve transparency. Similarly, the ReAct framework (Reason+Act) and related methods allow an LLM to reason about what action or tool to invoke at each step ([Large Language Model based Multi-Agents: A Survey of Progress and Challenges](https://arxiv.org/html/2402.01680v2#:~:text=,with%20verbal%20reinforcement%20learning%2C%202023)). In the context of MEUs, an LLM-based agent can use a chain-of-thought to decide: (1) identify the subject in the given scenario, (2) check if the condition applies, then (3) determine if the constraint (obligation/prohibition) has been violated – only flagging a violation if all criteria align. This mirrors how a human compliance officer might mentally walk through a checklist for each rule.

**Planning and Tool Use:** Executing legal rules may require pulling in external information – for example, querying a database of transactions or looking up definitions. Recent research on **LLM agents with tool-use** shows that models can augment their capabilities by calling APIs, search engines, or knowledge bases as needed ([Large Language Model based Multi-Agents: A Survey of Progress and Challenges](https://arxiv.org/html/2402.01680v2#:~:text=%23%23%20Tool)). In our framework, the LLM agent managing an MEU could invoke tools: e.g. a *calendar API* to check a filing deadline (time calculation), or a *knowledge graph query* to retrieve a referenced threshold from regulations. Multi-step planning is critical here. Ruan *et al.* (2023) introduce the *TPTU* paradigm (Task Planning and Tool Usage) explicitly to improve LLM agents’ ability to decompose tasks and use tools in real-world environments ([Large Language Model based Multi-Agents: A Survey of Progress and Challenges](https://arxiv.org/html/2402.01680v2#:~:text=,with%20verbal%20reinforcement%20learning%2C%202023)). The LLM first **plans** the sequence of actions (e.g. “First, find all facts about subject’s trades; next, check if any trade meets condition X; then verify if required report was filed”), and then **executes** these steps, possibly calling subordinate tools or functions at each step. This reflects a **workflow-oriented** approach: the agent treats rule enforcement as a mini workflow or program – precisely what MEUs are designed for (each MEU can be seen as a small program: *if condition and subject, then check constraint*).

**Multi-Agent Collaboration:** Complex compliance scenarios might benefit from multiple specialized LLM agents working in concert. For example, one agent could focus on parsing and interpreting the legal rule (transforming a text clause into a structured query), while another agent scans the company’s records or emails for facts that satisfy the condition. Multi-agent LLM systems are a burgeoning area of research, where agents can communicate and divide labor ([Large Language Model based Multi-Agents: A Survey of Progress and Challenges](https://arxiv.org/html/2402.01680v2#:~:text=,Guo%2C%20Wei%20He%2C%20Yiwen%20Ding)). Frameworks like **AutoGen** allow LLMs to converse with each other to solve problems collaboratively ([Large Language Model based Multi-Agents: A Survey of Progress and Challenges](https://arxiv.org/html/2402.01680v2#:~:text=,Guo%2C%20Wei%20He%2C%20Yiwen%20Ding)). In a compliance setting, we could envision an “Analyst Agent” and a “Knowledge Agent” dialoguing: the Analyst Agent might ask, *“Does client X meet the high-value transaction condition of rule Y?”*, and the Knowledge Agent can query the database to answer. Such interactions leverage *emergent specialization*, improving efficiency and accuracy. Coordination mechanisms (e.g. voting or cross-checking among agents) can also increase reliability, which is crucial in legal applications where mistakes are costly. In summary, LLM-based agents bring a powerful *planning and execution engine* to the table – capable of understanding rules, breaking down the compliance checking procedure into logical steps, and using external tools or even collaborating with peer agents to gather information and apply the rule. This AI workflow executes each MEU in a controlled, explainable manner, much like running a suite of unit tests against the world’s facts.

## Knowledge Representation and Reasoning via Graphs  
**Structured Knowledge for Rules:** Representing legal knowledge in structured forms is key to bridging symbolic reasoning with data. Each MEU, once extracted, can be viewed as a node or subgraph in a larger **knowledge graph** of the law. In such a graph, nodes might represent legal entities (companies, individuals), conditions (events, states of the world), and constraints (obligations, prohibitions), with labeled edges capturing their relations (e.g. *“Rule applies-to Person”* or *“Violation triggers Penalty”*). Knowledge graphs have been widely used in the legal AI domain to encode the rich interconnections in laws and regulations ([Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization](https://arxiv.org/html/2502.20364#:~:text=2,Research)). For instance, Sovrano *et al.* (2020) construct domain-specific legal graphs, and others fuse knowledge graphs with transformer models to create more **explainable legal research workflows** ([Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization](https://arxiv.org/html/2502.20364#:~:text=In%20the%20legal%20domain%2C%20researchers,specific%20graphs%20tailored%20to%20legal)). The advantage of a graph-based representation is that it provides a **global view** of all MEUs and their dependencies. If one rule references another, or if multiple MEUs share a common condition, these links are explicit in the graph. This enables the system (or an LLM agent) to navigate related rules, check prerequisites, or aggregate conditions across provisions.

**Integration of KGs with LLMs:** An important question is how LLM agents interact with the structured knowledge. One approach is **Retrieval-Augmented Generation (RAG)**, where the LLM queries a knowledge base or graph for relevant information during its reasoning process ([Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization](https://arxiv.org/html/2502.20364#:~:text=match%20at%20L260%20modern%20approaches,and%20efficient%20legal%20research%20workflows)) ([Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization](https://arxiv.org/html/2502.20364#:~:text=For%20additional%20context%2C%20the%20system,judicial%20interpretations%2C%20or%20precedent%20cases)). For compliance checking, the agent might retrieve from the graph the formal definition of a term in the MEU or find applicable threshold values defined elsewhere in the statutes. By grounding the LLM’s decisions in an authoritative knowledge graph, we curb the risk of hallucination and ensure consistency with the source of truth (the code of regulations). This kind of neuro-symbolic synergy is gaining traction: LLMs provide flexibility and language understanding, while symbolic formalisms (graphs, logic rules) provide precision and verifiability ([[PDF] LLM+AL: Bridging Large Language Models and Action Languages ...](https://ojs.aaai.org/index.php/AAAI/article/view/34597/36752#:~:text=,the%20symbolic%20reasoning%20strengths)). In practice, Sleimi *et al.* use semantic NLP to populate a legal knowledge base from text, which can then be queried for rule compliance ([Rethinking Legal Compliance Automation: Opportunities with Large Language Models](https://arxiv.org/html/2404.14356v1#:~:text=obligations%20to%20analyze%20policy%20documents,requirements%20from%20obligations%20in%20software)). Likewise, Amaral *et al.* build knowledge bases of privacy rules to automatically check GDPR obligations ([Rethinking Legal Compliance Automation: Opportunities with Large Language Models](https://arxiv.org/html/2404.14356v1#:~:text=references.%20Amaral%20et%20al.%C2%A0,obligations%20in%20software%20engineering%20contracts)). These examples show that **knowledge representation** can capture the essence of legal rules and enable automated reasoning over them. Knowledge graphs also facilitate **explanation**: if an MEU is violated, the graph can trace which specific condition or link failed (e.g. *“Transaction ABC exceeds the limit set in Rule 5.2”*), yielding human-readable justification.

**Expressive Logic and Constraints:** In financial and regulatory domains, knowledge graphs are often coupled with rule engines or logic programming for complex reasoning. A notable case is the Enterprise Knowledge Graph at the Central Bank of Italy, which encodes financial regulations and business rules in a Datalog-based language (Vadalog) ([Template-based Explainable Inference over High-Stakes Financial Knowledge Graphs](https://openproceedings.org/2025/conf/edbt/paper-135.pdf#:~:text=is%20critical%20is%20the%20Enterprise,natural%20language)). By encoding rules in a logical form, the system can perform inferencing – for example, deducing indirect ownership links or flagging market manipulation patterns – that goes beyond simple pattern matching. Each MEU could be translated into such a logical rule (with its subject, condition, and constraint becoming parts of a logical clause). Then, using a graph query or logic engine, we can execute all MEUs against a dataset of facts systematically. This approach has two benefits: (1) **Soundness** – logic engines ensure that a violation is identified only if it truly follows from the premises (subject and condition) being satisfied; and (2) **Transparency** – the path of reasoning (which rules fired, which facts triggered them) can be recorded. In academic literature, there is movement towards combining **graph-based knowledge** with LLM-driven reasoning to handle compliance tasks. For example, Casanovas *et al.* describe building a multilingual legal knowledge graph for EU compliance and using AI to query it in natural language ([Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization](https://arxiv.org/html/2502.20364#:~:text=In%20the%20legal%20domain%2C%20researchers,specific%20graphs%20tailored%20to%20legal)). Overall, robust knowledge representation (via graphs and logic) is the backbone that complements LLM agents. It provides the **memory** and **structure** for the agent to reason about MEUs, much like a well-indexed case library or statute book that the agent can consult instantly. By briefly anchoring each MEU in a knowledge graph, we gain a powerful hybrid: the precision of formal rules with the adaptability of language models.

## Compliance Automation in Finance and Accounting  
**Regulatory Compliance as a Use Case:** The financial and accounting sectors are rife with complex regulations—e.g. securities trading rules, anti-money-laundering (AML) laws, tax codes, and accounting standards (GAAP/IFRS). Compliance automation in this domain seeks to continuously monitor operations and ensure that every applicable rule is being followed, which is precisely the goal of executing MEUs with LLM agents. Unlike static code-based rule systems, an LLM-driven approach can interpret nuanced regulatory text and apply it to messy real-world data. This is crucial because financial regulations often contain *conditional clauses, exceptions, and thresholds* that a simple hard-coded program might misinterpret. By encoding these regulations as MEUs, we create a library of atomic checks—for example, an MEU might represent a rule like “**FINRA Rule 3310**: if a broker-dealer handles transactions above a certain size without an AML program, it’s a violation.” The LLM agent can take this MEU, parse a firm’s transaction logs (unstructured text or structured data), and determine if the scenario matches the subject (broker-dealer), condition (large transactions, no AML program) and thus flags the **constraint violation** ([An Evolving Landscape: Generative AI and Large Language Models in the Financial Industry | FINRA.org](https://www.finra.org/media-center/generative-ai-llm#:~:text=there,efficiencies%20in%20ongoing%20repetitive%20processes)). FINRA itself has acknowledged the potential of generative AI to act *“as an agent… to help create efficiencies in ongoing repetitive processes”* ([An Evolving Landscape: Generative AI and Large Language Models in the Financial Industry | FINRA.org](https://www.finra.org/media-center/generative-ai-llm#:~:text=there,efficiencies%20in%20ongoing%20repetitive%20processes)), which includes scanning for compliance issues. This indicates a receptiveness in industry to AI-assisted compliance monitoring.

**Cross-Jurisdiction and Domain Knowledge:** Financial compliance is global by nature. A multinational bank must follow **EU regulations** (e.g. MiFID II, GDPR for customer data), **US regulations** (SEC and FINRA rules, Sarbanes-Oxley for accounting), and **Chinese regulations** (e.g. CSRC and Beijing Stock Exchange listing rules) among others. Each set of rules can be decomposed into MEUs, and interestingly, many share common patterns (such as reporting obligations, capital requirements, etc.) albeit with different parameters. A well-structured knowledge base can link equivalent concepts across jurisdictions – for instance, associating an EU “market abuse” rule MEU with a similar US insider trading rule MEU. This opens the door for **transfer learning**: an LLM fine-tuned to check one jurisdiction’s rules might assist in another, by recognizing analogous rule structures. Recent advances in **legal benchmarks for LLMs** (e.g. *LegalBench*, a suite of tasks testing legal reasoning ([](https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA241230#:~:text=,Combining%20GPT))) underscore the importance of evaluating LLMs on regulatory compliance problems across diverse legal systems. By incorporating domain knowledge (like the structure of financial instruments, or the taxonomy of accounting entries) into the prompts or the knowledge graph, we give the LLM agent context to make accurate decisions. For example, an agent checking an IFRS accounting rule (say revenue recognition under IFRS 15) would benefit from knowing the corporate accounting hierarchy, which could be stored in a graph, as well as the definitions of terms like “contract asset” or “performance obligation” provided in the standards.

**Automation and Monitoring:** The ultimate aim of this approach is **real-time compliance monitoring**. In practice, a deployed system might continuously ingest company data (trades, emails, filings) and for each new event, trigger the relevant MEUs. Each MEU is like a sentry watching for a specific violation. Because MEUs are fine-grained, the system’s alerts are also fine-grained – instead of a generic warning that “Rule X might be violated”, it can pinpoint *which clause* and *why*. This improves the audibility and trust in AI compliance tools, as stakeholders can see the exact rule clause (MEU) that was triggered, along with the supporting evidence. In finance and accounting, such explainability is crucial for adoption due to strict oversight by regulators and auditors. Indeed, regulators in different regions are encouraging RegTech innovation to handle growing regulatory complexity. The European Union has funded projects like **Computable Law (CompuLaw)** to formalize laws for automation ([](https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA241230#:~:text=1This%20research%20was%20funded%20by,Legal%20Knowledge%20and%20Information%20Systems)), and China’s regulatory bodies are experimenting with AI compliance sandboxes for their exchanges. The integration of LLM agents with formal rule units aligns with these trends: it offers a path to **augment compliance teams** with AI co-pilots that can parse legal texts and cross-check transactions at a speed and scale unattainable by manual review. Early studies have shown that LLMs can assess legal documents for compliance with surprising competence ([Rethinking Legal Compliance Automation: Opportunities with Large Language Models](https://arxiv.org/html/2404.14356v1#:~:text=Despite%20the%20significant%20progress%20made,15)), though challenges remain in ensuring absolute reliability. By combining the strengths of rule-based systems (rigor and consistency) with those of LLMs (flexibility and understanding of context), compliance automation can achieve both **breadth and depth**. It can cover the breadth of regulations (thousands of MEUs across various laws) and examine the depth of each case (nuanced context, free-text justifications) without getting overwhelmed. As a result, financial institutions can respond to regulatory requirements more proactively – for example, detecting a suspicious trade and its reporting omission within minutes, or verifying that financial statements comply with the latest accounting standards before an audit. This cross-domain synthesis of legal formalism, AI planning, knowledge representation, and domain-specific compliance needs represents a promising foundation for next-generation RegTech systems that are *both intelligent and accountable*. 

**Citations:** The references marked in the text (e.g.,【40】,【23】) correspond to the following works: Ashley (2017) on AI and legal analytics; Billi *et al.* (2024) on hybrid LLM-rule systems ([](https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA241230#:~:text=Expert%20systems%20have%20been%20a,1%2C2%5D%2C%20which%20makes%20the)) ([](https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA241230#:~:text=reasoning%20pro%02cesses%2C%20these%20systems%20face,built%20on%20vast%20amounts%20of)); Janatian *et al.* (2023) on LLMs extracting structured legal representations ([[2311.04911] From Text to Structure: Using Large Language Models to Support the Development of Legal Expert Systems](https://arxiv.org/abs/2311.04911#:~:text=,legislation%2C%20according%20to%20the%20JusticeBot)) ([[2311.04911] From Text to Structure: Using Large Language Models to Support the Development of Legal Expert Systems](https://arxiv.org/abs/2311.04911#:~:text=methodology%20for%20legal%20decision%20support,that%20are%20transparent%20and%20explainable)); Yao *et al.* (2022) on chain-of-thought prompting ([Large Language Model based Multi-Agents: A Survey of Progress and Challenges](https://arxiv.org/html/2402.01680v2#:~:text=,Information%20Processing%20Systems%2C%2035%3A24824%E2%80%9324837%2C%202022)); Ruan *et al.* (2023) on task planning & tool use for LLM agents ([Large Language Model based Multi-Agents: A Survey of Progress and Challenges](https://arxiv.org/html/2402.01680v2#:~:text=,with%20verbal%20reinforcement%20learning%2C%202023)); Wu *et al.* (2023) on multi-agent Autogen framework ([Large Language Model based Multi-Agents: A Survey of Progress and Challenges](https://arxiv.org/html/2402.01680v2#:~:text=,08155%2C%202023)); Sovrano *et al.* (2020) and others on legal knowledge graphs ([Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization](https://arxiv.org/html/2502.20364#:~:text=2,Research)); Fiorelli *et al.* (2025) on Bank of Italy’s knowledge graph with Datalog rules ([Template-based Explainable Inference over High-Stakes Financial Knowledge Graphs](https://openproceedings.org/2025/conf/edbt/paper-135.pdf#:~:text=is%20critical%20is%20the%20Enterprise,natural%20language)); Guha *et al.* (2023) on the LegalBench benchmark ([](https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA241230#:~:text=,Combining%20GPT)) ([](https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA241230#:~:text=,4.%20Available%20from%3A%20https%3A%2F%2Fdoi.org%2F10.3233%2FFAIA230991)); and FINRA (2024) on the use of generative AI in finance ([An Evolving Landscape: Generative AI and Large Language Models in the Financial Industry | FINRA.org](https://www.finra.org/media-center/generative-ai-llm#:~:text=there,efficiencies%20in%20ongoing%20repetitive%20processes)). These works collectively underpin the methodology of decomposing legal rules into MEUs and using LLM agents for execution, demonstrating both the feasibility and the interdisciplinary nature of this approach.